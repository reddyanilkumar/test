





In [165]:



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns




In [166]:



user_df= pd.read_csv("train/users.csv")




In [167]:



sub_df= pd.read_csv("train/submissions.csv")




In [168]:



prob_df= pd.read_csv("train/problems.csv")




In [169]:



user_df.count()





Out[169]:

user_id         62530
skills          62271
solved_count    62530
attempts        62530
user_type       34215
dtype: int64



In [170]:



prob_df.count()





Out[170]:

problem_id      1002
level            768
accuracy        1002
solved_count    1002
error_count     1002
rating          1002
tag1             725
tag2             473
tag3             181
tag4              46
tag5               6
dtype: int64



In [171]:



sub_df.count()





Out[171]:

user_id           1198131
problem_id        1198131
solved_status     1198131
result            1198131
language_used     1198131
execution_time    1198131
dtype: int64



In [172]:



merged_inner = pd.merge(left=user_df,right=sub_df,left_on='user_id', right_on='user_id')




In [173]:



merged_inner.drop('language_used', axis=1, inplace=True)




In [174]:



merged_inner.drop('result', axis=1, inplace=True)




In [175]:



merged_inner.drop('execution_time', axis=1, inplace=True)




In [176]:



merged_inner.drop_duplicates(inplace=True)




In [177]:



merged_inner.drop('user_type', axis=1, inplace=True)




In [178]:



merged_inner.head(20)





Out[178]:





user_id

skills

solved_count

attempts

problem_id

solved_status



0
1427919 C++ 0 11 913736 AT 

11
1034704 C 3 11 906741 AT 

13
1034704 C 3 11 906741 SO 

15
1034704 C 3 11 909152 SO 

17
1034704 C 3 11 909145 SO 

18
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 907301 AT 

21
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 920126 SO 

23
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903666 SO 

29
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 906315 AT 

34
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903790 SO 

36
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903790 AT 

38
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903639 SO 

40
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903639 AT 

42
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 926728 AT 

43
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903788 SO 

46
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 907300 AT 

47
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903786 AT 

48
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903786 SO 

64
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 905488 AT 

69
903633 C|PHP|Java|Python|Text|JavaScript|C++|Perl|C#|... 66 260 903905 SO 



In [179]:



merged_inner.corr()





Out[179]:





user_id

solved_count

attempts

problem_id



user_id
1.000000 -0.120974 -0.168427 0.351435 

solved_count
-0.120974 1.000000 0.737944 0.039585 

attempts
-0.168427 0.737944 1.000000 -0.017755 

problem_id
0.351435 0.039585 -0.017755 1.000000 



In [180]:



merged_inner1 = pd.merge(left=merged_inner,right=prob_df,left_on='problem_id', right_on='problem_id')




In [181]:



merged_inner1.count()





Out[181]:

user_id           516086
skills            516086
solved_count_x    516086
attempts          516086
problem_id        516086
solved_status     516086
level             475645
accuracy          516086
solved_count_y    516086
error_count       516086
rating            516086
tag1              448577
tag2              300295
tag3               97188
tag4               20003
tag5                4782
dtype: int64



In [182]:



merged_inner1.drop('tag5', axis=1, inplace=True)




In [183]:



merged_inner1.drop('tag4', axis=1, inplace=True)




In [184]:



merged_inner1.drop('tag3', axis=1, inplace=True)




In [185]:



merged_inner1.drop('tag2', axis=1, inplace=True)




In [186]:



merged_inner1.drop('tag1', axis=1, inplace=True)




In [187]:



merged_inner1.drop('skills', axis=1, inplace=True)




In [188]:



merged_inner1.drop('level', axis=1, inplace=True)




In [189]:



merged_inner1.head()





Out[189]:





user_id

solved_count_x

attempts

problem_id

solved_status

accuracy

solved_count_y

error_count

rating



0
1427919 0 11 913736 AT 0.21 524 7868 4 

1
1187633 14 20 913736 AT 0.21 524 7868 4 

2
1187633 14 20 913736 SO 0.21 524 7868 4 

3
1165859 2 14 913736 AT 0.21 524 7868 4 

4
1034822 6 11 913736 AT 0.21 524 7868 4 



In [190]:



merged_inner1.solved_status.unique()





Out[190]:

array(['AT', 'SO', 'UK'], dtype=object)



In [191]:



merged_inner1 = merged_inner1[merged_inner1.solved_status != 'UK']




In [192]:



def transform_solved_status(ss):
    if (ss == 'SO'):
        return 1
    if (ss == 'AT'):
        return 0




In [193]:



merged_inner1['solved_status'] = merged_inner1['solved_status'].map(transform_solved_status)




In [216]:



merged_inner1.head()





Out[216]:





user_id

solved_count_x

attempts

problem_id

solved_status

accuracy

rating



0
1427919 0 11 913736 0 0.21 4 

1
1187633 14 20 913736 0 0.21 4 

2
1187633 14 20 913736 1 0.21 4 

3
1165859 2 14 913736 0 0.21 4 

4
1034822 6 11 913736 0 0.21 4 



In [149]:



from sklearn.cross_validation import train_test_split
X_train,X_test,Y_train,y_test = train_test_split(merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)




In [217]:



from sklearn.cross_validation import train_test_split
X_train,X_test,Y_train,y_test = train_test_split(merged_inner1[['solved_count_x','accuracy','rating']],merged_inner1.solved_status)




In [218]:



X_train.head()





Out[218]:





solved_count_x

accuracy

rating



465507
2 0.88 1.8 

135062
121 0.93 4.1 

290443
44 0.63 0.0 

458320
2 0.42 5.0 

244127
1 0.54 0.0 



In [219]:



from sklearn.svm import LinearSVC




In [220]:



svm = LinearSVC(C=0.1)




In [221]:



svm.fit(X_train,Y_train)





Out[221]:

LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)



In [222]:



svm.score(X_train,Y_train)





Out[222]:

0.69894381662507044



In [223]:



svm.score(X_test,y_test)





Out[223]:

0.69857927902091943



In [224]:



from sklearn.ensemble import RandomForestClassifier




In [225]:



rf = RandomForestClassifier(n_estimators=20,random_state=1)




In [226]:



rf.fit(X_train,Y_train)






---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-226-913f85195773> in <module>()
----> 1 rf.fit(X_train,Y_train)

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in fit(self, X, y, sample_weight)
    271                     t, self, X, y, sample_weight, i, len(trees),
    272                     verbose=self.verbose, class_weight=self.class_weight)
--> 273                 for i, t in enumerate(trees))
    274 
    275             # Collect newly grown trees

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __call__(self, iterable)
    657             self._iterating = True
    658             for function, args, kwargs in iterable:
--> 659                 self.dispatch(function, args, kwargs)
    660 
    661             if pre_dispatch == "all" or n_jobs == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in dispatch(self, func, args, kwargs)
    404         """
    405         if self._pool is None:
--> 406             job = ImmediateApply(func, args, kwargs)
    407             index = len(self._jobs)
    408             if not _verbosity_filter(index, self.verbose):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __init__(self, func, args, kwargs)
    138         # Don't delay the application, to avoid keeping the input
    139         # arguments in memory
--> 140         self.results = func(*args, **kwargs)
    141 
    142     def get(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in _parallel_build_trees(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)
     92             curr_sample_weight *= compute_sample_weight('auto', y, indices)
     93 
---> 94         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
     95 
     96         tree.indices_ = sample_counts > 0.

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\tree\tree.pyc in fit(self, X, y, sample_weight, check_input)
    168 
    169             for k in range(self.n_outputs_):
--> 170                 classes_k, y[:, k] = np.unique(y[:, k], return_inverse=True)
    171                 self.classes_.append(classes_k)
    172                 self.n_classes_.append(classes_k.shape[0])

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\numpy\lib\arraysetops.pyc in unique(ar, return_index, return_inverse, return_counts)
    192     if optional_indices:
    193         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
--> 194         aux = ar[perm]
    195     else:
    196         ar.sort()

MemoryError: 



In [209]:



rf.score(X_train,Y_train)






---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-209-560e648697a0> in <module>()
----> 1 rf.score(X_train,Y_train)

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\base.pyc in score(self, X, y, sample_weight)
    293         """
    294         from .metrics import accuracy_score
--> 295         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)
    296 
    297 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in predict(self, X)
    460         # for 1d.
    461         X = check_array(X, ensure_2d=False, accept_sparse="csr")
--> 462         proba = self.predict_proba(X)
    463 
    464         if self.n_outputs_ == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in predict_proba(self, X)
    511                              backend="threading")(
    512             delayed(_parallel_helper)(e, 'predict_proba', X, check_input=False)
--> 513             for e in self.estimators_)
    514 
    515         # Reduce

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __call__(self, iterable)
    657             self._iterating = True
    658             for function, args, kwargs in iterable:
--> 659                 self.dispatch(function, args, kwargs)
    660 
    661             if pre_dispatch == "all" or n_jobs == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in dispatch(self, func, args, kwargs)
    404         """
    405         if self._pool is None:
--> 406             job = ImmediateApply(func, args, kwargs)
    407             index = len(self._jobs)
    408             if not _verbosity_filter(index, self.verbose):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __init__(self, func, args, kwargs)
    138         # Don't delay the application, to avoid keeping the input
    139         # arguments in memory
--> 140         self.results = func(*args, **kwargs)
    141 
    142     def get(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in _parallel_helper(obj, methodname, *args, **kwargs)
    104 def _parallel_helper(obj, methodname, *args, **kwargs):
    105     """Private helper to workaround Python 2 pickle limitations"""
--> 106     return getattr(obj, methodname)(*args, **kwargs)
    107 
    108 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\tree\tree.pyc in predict_proba(self, X, check_input)
    590                              % (self.n_features_, n_features))
    591 
--> 592         proba = self.tree_.predict(X)
    593 
    594         if self.n_outputs_ == 1:

sklearn/tree/_tree.pyx in sklearn.tree._tree.Tree.predict (sklearn\tree\_tree.c:24468)()

sklearn/tree/_tree.pyx in sklearn.tree._tree.Tree.predict (sklearn\tree\_tree.c:24340)()

MemoryError: 



In [160]:



rf.score(X_test,y_test)





Out[160]:

0.51759043241693081



In [161]:



def importances(estimator, col_array, title): 
    # Calculate the feature ranking - Top 10
    importances = estimator.feature_importances_
    indices = np.argsort(importances)[::-1]
    print "%s Top 20 Important Features\n" %title
    for f in range(7):
        print("%d. %s (%f)" % (f + 1, col_array.columns[indices[f]], importances[indices[f]]))
#Mean Feature Importance
    print "\nMean Feature Importance %.6f" %np.mean(importances)




In [162]:



importances(rf, merged_inner1, "Cover Type (Initial RF)")






Cover Type (Initial RF) Top 20 Important Features

1. user_id (0.751141)
2. problem_id (0.198329)
3. solved_status (0.050530)




---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-162-a2643faa280f> in <module>()
----> 1 importances(rf, merged_inner1, "Cover Type (Initial RF)")

<ipython-input-161-42e394bc7990> in importances(estimator, col_array, title)
      5     print "%s Top 20 Important Features\n" %title
      6     for f in range(7):
----> 7         print("%d. %s (%f)" % (f + 1, col_array.columns[indices[f]], importances[indices[f]]))
      8 #Mean Feature Importance
      9     print "\nMean Feature Importance %.6f" %np.mean(importances)

IndexError: index 3 is out of bounds for axis 0 with size 3



In [215]:



merged_inner1.drop('error_count', axis=1, inplace=True)




In [143]:



merged_inner1.drop('solved_count_x', axis=1, inplace=True)




In [214]:



merged_inner1.drop('solved_count_y', axis=1, inplace=True)




In [145]:



merged_inner1.drop('accuracy', axis=1, inplace=True)




In [228]:



merged_inner1.drop('attempts', axis=1, inplace=True)




In [229]:



from sklearn.neighbors import KNeighborsClassifier




In [230]:



cls = KNeighborsClassifier()
cls.fit(X_train,Y_train)
cls.score(X_test,y_test)





Out[230]:

0.67350545268526341



In [212]:



from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(rf,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))






---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-212-917c5125f946> in <module>()
      1 from sklearn.cross_validation import cross_val_score
      2 import numpy as np
----> 3 scores = cross_val_score(rf,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
      4 print (scores)
      5 print (np.mean(scores))

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\cross_validation.pyc in cross_val_score(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)
   1359                                               train, test, verbose, None,
   1360                                               fit_params)
-> 1361                       for train, test in cv)
   1362     return np.array(scores)[:, 0]
   1363 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __call__(self, iterable)
    657             self._iterating = True
    658             for function, args, kwargs in iterable:
--> 659                 self.dispatch(function, args, kwargs)
    660 
    661             if pre_dispatch == "all" or n_jobs == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in dispatch(self, func, args, kwargs)
    404         """
    405         if self._pool is None:
--> 406             job = ImmediateApply(func, args, kwargs)
    407             index = len(self._jobs)
    408             if not _verbosity_filter(index, self.verbose):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __init__(self, func, args, kwargs)
    138         # Don't delay the application, to avoid keeping the input
    139         # arguments in memory
--> 140         self.results = func(*args, **kwargs)
    141 
    142     def get(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\cross_validation.pyc in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)
   1457             estimator.fit(X_train, **fit_params)
   1458         else:
-> 1459             estimator.fit(X_train, y_train, **fit_params)
   1460 
   1461     except Exception as e:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in fit(self, X, y, sample_weight)
    271                     t, self, X, y, sample_weight, i, len(trees),
    272                     verbose=self.verbose, class_weight=self.class_weight)
--> 273                 for i, t in enumerate(trees))
    274 
    275             # Collect newly grown trees

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __call__(self, iterable)
    657             self._iterating = True
    658             for function, args, kwargs in iterable:
--> 659                 self.dispatch(function, args, kwargs)
    660 
    661             if pre_dispatch == "all" or n_jobs == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in dispatch(self, func, args, kwargs)
    404         """
    405         if self._pool is None:
--> 406             job = ImmediateApply(func, args, kwargs)
    407             index = len(self._jobs)
    408             if not _verbosity_filter(index, self.verbose):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __init__(self, func, args, kwargs)
    138         # Don't delay the application, to avoid keeping the input
    139         # arguments in memory
--> 140         self.results = func(*args, **kwargs)
    141 
    142     def get(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\ensemble\forest.pyc in _parallel_build_trees(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)
     92             curr_sample_weight *= compute_sample_weight('auto', y, indices)
     93 
---> 94         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
     95 
     96         tree.indices_ = sample_counts > 0.

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\tree\tree.pyc in fit(self, X, y, sample_weight, check_input)
    168 
    169             for k in range(self.n_outputs_):
--> 170                 classes_k, y[:, k] = np.unique(y[:, k], return_inverse=True)
    171                 self.classes_.append(classes_k)
    172                 self.n_classes_.append(classes_k.shape[0])

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\numpy\lib\arraysetops.pyc in unique(ar, return_index, return_inverse, return_counts)
    192     if optional_indices:
    193         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
--> 194         aux = ar[perm]
    195     else:
    196         ar.sort()

MemoryError: 



In [213]:



from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(cls,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))






---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-213-bfeabb846b3c> in <module>()
      1 from sklearn.cross_validation import cross_val_score
      2 import numpy as np
----> 3 scores = cross_val_score(cls,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
      4 print (scores)
      5 print (np.mean(scores))

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\indexing.pyc in __getitem__(self, key)
     66                 pass
     67 
---> 68             return self._getitem_tuple(key)
     69         else:
     70             return self._getitem_axis(key, axis=0)

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\indexing.pyc in _getitem_tuple(self, tup)
    718                 continue
    719 
--> 720             retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
    721 
    722         return retval

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\indexing.pyc in _getitem_axis(self, key, axis)
    913                 raise ValueError('Cannot index with multidimensional key')
    914 
--> 915             return self._getitem_iterable(key, axis=axis)
    916         else:
    917             if is_integer(key):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\indexing.pyc in _getitem_iterable(self, key, axis)
    938             key = check_bool_indexer(labels, key)
    939             inds, = key.nonzero()
--> 940             return self.obj.take(inds, axis=axis, convert=False)
    941         else:
    942             if isinstance(key, Index):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\generic.pyc in take(self, indices, axis, convert, is_copy)
   1356         new_data = self._data.take(indices,
   1357                                    axis=self._get_block_manager_axis(axis),
-> 1358                                    convert=True, verify=True)
   1359         result = self._constructor(new_data).__finalize__(self)
   1360 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in take(self, indexer, axis, verify, convert)
   3273         new_labels = self.axes[axis].take(indexer)
   3274         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,
-> 3275                                     axis=axis, allow_dups=True)
   3276 
   3277     def merge(self, other, lsuffix='', rsuffix=''):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy)
   3155         if axis == 0:
   3156             new_blocks = self._slice_take_blocks_ax0(
-> 3157                 indexer, fill_tuple=(fill_value,))
   3158         else:
   3159             new_blocks = [blk.take_nd(indexer, axis=axis,

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in _slice_take_blocks_ax0(self, slice_or_indexer, fill_tuple)
   3236                     blocks.append(blk.take_nd(
   3237                         blklocs[mgr_locs.indexer], axis=0,
-> 3238                         new_mgr_locs=mgr_locs, fill_tuple=None))
   3239 
   3240         return blocks

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in take_nd(self, indexer, axis, new_mgr_locs, fill_tuple)
    851             fill_value = self.fill_value
    852             new_values = com.take_nd(self.get_values(), indexer, axis=axis,
--> 853                                      allow_fill=False)
    854         else:
    855             fill_value = fill_tuple[0]

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\common.pyc in take_nd(arr, indexer, axis, out, fill_value, mask_info, allow_fill)
    836             out = np.empty(out_shape, dtype=dtype, order='F')
    837         else:
--> 838             out = np.empty(out_shape, dtype=dtype)
    839 
    840     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype,

MemoryError: 



In [231]:



from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(svm,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))






---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-231-f7e99e615668> in <module>()
      1 from sklearn.cross_validation import cross_val_score
      2 import numpy as np
----> 3 scores = cross_val_score(svm,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
      4 print (scores)
      5 print (np.mean(scores))

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\cross_validation.pyc in cross_val_score(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)
   1359                                               train, test, verbose, None,
   1360                                               fit_params)
-> 1361                       for train, test in cv)
   1362     return np.array(scores)[:, 0]
   1363 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __call__(self, iterable)
    657             self._iterating = True
    658             for function, args, kwargs in iterable:
--> 659                 self.dispatch(function, args, kwargs)
    660 
    661             if pre_dispatch == "all" or n_jobs == 1:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in dispatch(self, func, args, kwargs)
    404         """
    405         if self._pool is None:
--> 406             job = ImmediateApply(func, args, kwargs)
    407             index = len(self._jobs)
    408             if not _verbosity_filter(index, self.verbose):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\externals\joblib\parallel.pyc in __init__(self, func, args, kwargs)
    138         # Don't delay the application, to avoid keeping the input
    139         # arguments in memory
--> 140         self.results = func(*args, **kwargs)
    141 
    142     def get(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\cross_validation.pyc in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)
   1457             estimator.fit(X_train, **fit_params)
   1458         else:
-> 1459             estimator.fit(X_train, y_train, **fit_params)
   1460 
   1461     except Exception as e:

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\svm\classes.pyc in fit(self, X, y)
    198 
    199         X, y = check_X_y(X, y, accept_sparse='csr',
--> 200                          dtype=np.float64, order="C")
    201         self.classes_ = np.unique(y)
    202 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\utils\validation.pyc in check_X_y(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)
    442     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,
    443                     ensure_2d, allow_nd, ensure_min_samples,
--> 444                     ensure_min_features)
    445     if multi_output:
    446         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\sklearn\utils\validation.pyc in check_array(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)
    335     else:
    336         if ensure_2d:
--> 337             array = np.atleast_2d(array)
    338         if dtype_numeric:
    339             if hasattr(array, "dtype") and getattr(array.dtype, "kind", None) == "O":

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\numpy\core\shape_base.pyc in atleast_2d(*arys)
     97     res = []
     98     for ary in arys:
---> 99         ary = asanyarray(ary)
    100         if len(ary.shape) == 0 :
    101             result = ary.reshape(1, 1)

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\numpy\core\numeric.pyc in asanyarray(a, dtype, order)
    512 
    513     """
--> 514     return array(a, dtype, copy=False, order=order, subok=True)
    515 
    516 def ascontiguousarray(a, dtype=None):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\generic.pyc in __array__(self, dtype)
    738 
    739     def __array__(self, dtype=None):
--> 740         return _values_from_object(self)
    741 
    742     def __array_wrap__(self, result, context=None):

pandas\lib.pyx in pandas.lib.values_from_object (pandas\lib.c:4148)()

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\generic.pyc in get_values(self)
   2331     def get_values(self):
   2332         """ same as values (but handles sparseness conversions) """
-> 2333         return self.as_matrix()
   2334 
   2335     def get_dtype_counts(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\generic.pyc in as_matrix(self, columns)
   2304         self._consolidate_inplace()
   2305         if self._AXIS_REVERSED:
-> 2306             return self._data.as_matrix(columns).T
   2307         return self._data.as_matrix(columns)
   2308 

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in as_matrix(self, items)
   2711             return mgr.blocks[0].get_values()
   2712         else:
-> 2713             return mgr._interleave()
   2714 
   2715     def _interleave(self):

C:\Users\anilkumar_reddy01\AppData\Local\Continuum\Anaconda\lib\site-packages\pandas\core\internals.pyc in _interleave(self)
   2720         dtype = _interleaved_dtype(self.blocks)
   2721 
-> 2722         result = np.empty(self.shape, dtype=dtype)
   2723 
   2724         if result.shape[0] == 0:

MemoryError: 



In [102]:



merged_inner1





Out[102]:





user_id

attempts

problem_id

solved_status

rating



0
1427919 11 913736 0 4.0 

1
1187633 20 913736 0 4.0 

2
1187633 20 913736 1 4.0 

3
1165859 14 913736 0 4.0 

4
1034822 11 913736 0 4.0 

5
1384250 11 913736 0 4.0 

6
1428122 1 913736 0 4.0 

7
1166111 1 913736 0 4.0 

8
1166158 42 913736 0 4.0 

9
1144005 18 913736 0 4.0 

10
1035196 19 913736 0 4.0 

11
1035196 19 913736 1 4.0 

12
1035226 44 913736 1 4.0 

13
1035270 14 913736 0 4.0 

14
1166351 66 913736 0 4.0 

15
1166430 2 913736 1 4.0 

16
1384339 19 913736 0 4.0 

17
1166476 27 913736 0 4.0 

18
1428624 1 913736 0 4.0 

19
1035532 30 913736 0 4.0 

20
1035541 24 913736 0 4.0 

21
1035592 14 913736 0 4.0 

22
1166670 1 913736 0 4.0 

23
1035620 13 913736 0 4.0 

24
1166694 3 913736 0 4.0 

25
1078552 8 913736 0 4.0 

26
947488 77 913736 0 4.0 

27
947488 77 913736 1 4.0 

28
904686 21 913736 0 4.0 

29
1166874 6 913736 1 4.0 

...
... ... ... ... ... 

516056
1131415 166 935846 1 2.5 

516057
1135792 72 935846 0 2.5 

516058
1009369 163 935846 1 2.5 

516059
1337012 5 935846 1 2.5 

516060
1275822 103 935846 1 2.5 

516061
1276572 5 935846 1 2.5 

516062
1409736 419 935846 1 2.5 

516063
1155218 187 935846 1 2.5 

516064
1099417 130 935846 1 2.5 

516065
1293851 144 935846 1 2.5 

516066
942937 56 906717 1 0.0 

516067
955565 16 906717 0 0.0 

516068
954615 16 906717 1 0.0 

516069
959602 66 906717 1 0.0 

516070
967270 8 906717 1 0.0 

516071
945555 85 906717 1 0.0 

516072
1207522 50 913270 1 0.0 

516073
1081207 172 913270 1 0.0 

516074
952684 469 913270 1 0.0 

516075
952684 469 913270 0 0.0 

516076
1088137 194 913270 0 0.0 

516077
1088166 457 913270 1 0.0 

516078
1099144 38 913270 1 0.0 

516079
1100558 112 913270 1 0.0 

516080
1009212 2 913270 1 0.0 

516081
1012026 151 913270 1 0.0 

516082
1081960 16 913270 1 0.0 

516083
1016727 141 913270 1 0.0 

516084
968968 158 937778 1 4.1 

516085
977865 6 917940 1 0.0 

516073 rows Ã— 5 columns



In [ ]:



 

