
In [2]:

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

In [3]:

user_df= pd.read_csv("train/users.csv")
prob_df= pd.read_csv("train/problems.csv")
sub_df= pd.read_csv("train/submissions.csv")

In [4]:

test_user_df= pd.read_csv("test/users.csv")
test_prob_df= pd.read_csv("test/problems.csv")
test_sub_df= pd.read_csv("test/test.csv")

In [5]:

test_prob_df.count()

Out[5]:

problem_id      956
level           752
accuracy        956
solved_count    956
error_count     956
rating          956
tag1            666
tag2            422
tag3            158
tag4             41
tag5              7
dtype: int64

In [6]:

test_sub_df.count()

Out[6]:

Id            35618
user_id       35618
problem_id    35618
dtype: int64

In [7]:

test_user_df.count()

Out[7]:

user_id         15279
skills          15279
solved_count    15279
attempts        15279
user_type        8459
dtype: int64

In [8]:

user_df.count()

Out[8]:

user_id         62530
skills          62271
solved_count    62530
attempts        62530
user_type       34215
dtype: int64

In [9]:

prob_df.count()

Out[9]:

problem_id      1002
level            768
accuracy        1002
solved_count    1002
error_count     1002
rating          1002
tag1             725
tag2             473
tag3             181
tag4              46
tag5               6
dtype: int64

In [10]:

sub_df.count()

Out[10]:

user_id           1198131
problem_id        1198131
solved_status     1198131
result            1198131
language_used     1198131
execution_time    1198131
dtype: int64

In [11]:

merged_inner = pd.merge(user_df,sub_df,on='user_id')

In [12]:

test_merged_inner = pd.merge(test_user_df,test_sub_df,on='user_id')

In [13]:

test_merged_inner1 = pd.merge(left=test_merged_inner,right=test_prob_df,left_on='problem_id', right_on='problem_id')

In [14]:

test_merged_inner1.count()

Out[14]:

user_id           35618
skills            35618
solved_count_x    35618
attempts          35618
user_type         20550
Id                35618
problem_id        35618
level             32167
accuracy          35618
solved_count_y    35618
error_count       35618
rating            35618
tag1              27502
tag2              16562
tag3               4042
tag4                673
tag5                280
dtype: int64

In [15]:

merged_inner.head()

Out[15]:
	user_id 	skills 	solved_count 	attempts 	user_type 	problem_id 	solved_status 	result 	language_used 	execution_time
0 	1427919 	C++ 	0 	11 	W 	913736 	AT 	PAC 	C++ 	0.5874
1 	1427919 	C++ 	0 	11 	W 	913736 	AT 	PAC 	C++ 	0.5603
2 	1427919 	C++ 	0 	11 	W 	913736 	AT 	PAC 	C++ 	0.5696
3 	1427919 	C++ 	0 	11 	W 	913736 	AT 	PAC 	C++ 	0.5666
4 	1427919 	C++ 	0 	11 	W 	913736 	AT 	PAC 	C++ 	0.5656
In [15]:

merged_inner.drop('language_used', axis=1, inplace=True)
merged_inner.drop('result', axis=1, inplace=True)
merged_inner.drop('execution_time', axis=1, inplace=True)

In [16]:

merged_inner.drop_duplicates(inplace=True)

In [17]:

merged_inner.drop('user_type', axis=1, inplace=True)

In [18]:

test_merged_inner1.drop('user_type', axis=1, inplace=True)

In [19]:

merged_inner.head()

Out[19]:
	user_id 	skills 	solved_count 	attempts 	problem_id 	solved_status
0 	1427919 	C++ 	0 	11 	913736 	AT
11 	1034704 	C 	3 	11 	906741 	AT
13 	1034704 	C 	3 	11 	906741 	SO
15 	1034704 	C 	3 	11 	909152 	SO
17 	1034704 	C 	3 	11 	909145 	SO
In [20]:

test_merged_inner1.head()

Out[20]:
	user_id 	skills 	solved_count_x 	attempts 	Id 	problem_id 	level 	accuracy 	solved_count_y 	error_count 	rating 	tag1 	tag2 	tag3 	tag4 	tag5
0 	1444303 	Python 	0 	5 	14425 	940002 	E 	0.42 	63 	371 	3.7 	Ad-Hoc 	Basic Programming 	Implementation 	NaN 	NaN
1 	1461057 	Python 	0 	2 	18638 	940002 	E 	0.42 	63 	371 	3.7 	Ad-Hoc 	Basic Programming 	Implementation 	NaN 	NaN
2 	1002312 	Python|PHP 	0 	5 	9929 	940002 	E 	0.42 	63 	371 	3.7 	Ad-Hoc 	Basic Programming 	Implementation 	NaN 	NaN
3 	1002353 	Python 	14 	6 	20229 	940002 	E 	0.42 	63 	371 	3.7 	Ad-Hoc 	Basic Programming 	Implementation 	NaN 	NaN
4 	1068032 	Python|C|Java|C++ 	84 	36 	25139 	940002 	E 	0.42 	63 	371 	3.7 	Ad-Hoc 	Basic Programming 	Implementation 	NaN 	NaN
In [21]:

merged_inner.corr()

Out[21]:
	user_id 	solved_count 	attempts 	problem_id
user_id 	1.000000 	-0.120974 	-0.168427 	0.351435
solved_count 	-0.120974 	1.000000 	0.737944 	0.039585
attempts 	-0.168427 	0.737944 	1.000000 	-0.017755
problem_id 	0.351435 	0.039585 	-0.017755 	1.000000
In [23]:

corr = merged_inner.corr()[merged_inner.corr() < 1].abs()
corr.sort(ascending=False)
corr.head()

Out[23]:
	user_id 	solved_count 	attempts 	problem_id
user_id 	NaN 	0.120974 	0.168427 	0.351435
solved_count 	0.120974 	NaN 	0.737944 	0.039585
attempts 	0.168427 	0.737944 	NaN 	0.017755
problem_id 	0.351435 	0.039585 	0.017755 	NaN
In [24]:

merged_inner1 = pd.merge(left=merged_inner,right=prob_df,left_on='problem_id', right_on='problem_id')

In [25]:

merged_inner1.count()

Out[25]:

user_id           516086
skills            516086
solved_count_x    516086
attempts          516086
problem_id        516086
solved_status     516086
level             475645
accuracy          516086
solved_count_y    516086
error_count       516086
rating            516086
tag1              448577
tag2              300295
tag3               97188
tag4               20003
tag5                4782
dtype: int64

In [26]:

merged_inner1.drop('tag5', axis=1, inplace=True)

merged_inner1.drop('tag4', axis=1, inplace=True)

merged_inner1.drop('tag3', axis=1, inplace=True)

merged_inner1.drop('tag2', axis=1, inplace=True)

merged_inner1.drop('tag1', axis=1, inplace=True)

In [27]:

test_merged_inner1.drop('tag5', axis=1, inplace=True)

test_merged_inner1.drop('tag4', axis=1, inplace=True)

test_merged_inner1.drop('tag3', axis=1, inplace=True)

test_merged_inner1.drop('tag2', axis=1, inplace=True)

test_merged_inner1.drop('tag1', axis=1, inplace=True)

In [28]:

merged_inner1.drop('skills', axis=1, inplace=True)
#merged_inner1.drop('level', axis=1, inplace=True)

In [29]:

test_merged_inner1.drop('skills', axis=1, inplace=True)
#test_merged_inner1.drop('level', axis=1, inplace=True)

In [30]:

merged_inner1.count()

Out[30]:

user_id           516086
solved_count_x    516086
attempts          516086
problem_id        516086
solved_status     516086
level             475645
accuracy          516086
solved_count_y    516086
error_count       516086
rating            516086
dtype: int64

In [31]:

test_merged_inner1.head()

Out[31]:
	user_id 	solved_count_x 	attempts 	Id 	problem_id 	level 	accuracy 	solved_count_y 	error_count 	rating
0 	1444303 	0 	5 	14425 	940002 	E 	0.42 	63 	371 	3.7
1 	1461057 	0 	2 	18638 	940002 	E 	0.42 	63 	371 	3.7
2 	1002312 	0 	5 	9929 	940002 	E 	0.42 	63 	371 	3.7
3 	1002353 	14 	6 	20229 	940002 	E 	0.42 	63 	371 	3.7
4 	1068032 	84 	36 	25139 	940002 	E 	0.42 	63 	371 	3.7
In [32]:

merged_inner1.solved_status.unique()

Out[32]:

array(['AT', 'SO', 'UK'], dtype=object)

In [33]:

merged_inner1 = merged_inner1[merged_inner1.solved_status != 'UK']

In [34]:

def transform_solved_status(ss):
    if (ss == 'SO'):
        return 1
    if (ss == 'AT'):
        return 0

In [35]:

merged_inner1['solved_status'] = merged_inner1['solved_status'].map(transform_solved_status)

In [36]:

merged_inner1.head()

Out[36]:
	user_id 	solved_count_x 	attempts 	problem_id 	solved_status 	level 	accuracy 	solved_count_y 	error_count 	rating
0 	1427919 	0 	11 	913736 	0 	M 	0.21 	524 	7868 	4
1 	1187633 	14 	20 	913736 	0 	M 	0.21 	524 	7868 	4
2 	1187633 	14 	20 	913736 	1 	M 	0.21 	524 	7868 	4
3 	1165859 	2 	14 	913736 	0 	M 	0.21 	524 	7868 	4
4 	1034822 	6 	11 	913736 	0 	M 	0.21 	524 	7868 	4
In [72]:

merged_inner1['accuracy'] = (merged_inner1.accuracy*10).apply(np.round)

/home/anil/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  if __name__ == '__main__':

In [214]:

test_merged_inner1['accuracy'] = (test_merged_inner1.accuracy*10).apply(np.round)

In [36]:

test_merged_inner1.accuracy.unique()

Out[36]:

array([ 0.42,  0.32,  0.45,  0.92,  0.74,  0.89,  0.91,  0.87,  0.3 ,
        0.25,  0.56,  0.71,  0.46,  0.43,  0.6 ,  0.53,  0.85,  0.77,
        0.84,  0.52,  0.96,  0.93,  0.8 ,  0.57,  0.21,  0.35,  0.28,
        0.55,  0.62,  0.76,  0.63,  0.9 ,  0.83,  0.95,  0.66,  0.69,
        0.41,  0.12,  0.58,  0.79,  0.06,  0.09,  0.26,  0.39,  0.64,
        0.5 ,  0.47,  0.37,  0.11,  0.94,  0.18,  0.33,  0.7 ,  0.67,
        0.07,  0.65,  0.31,  0.75,  0.54,  0.36,  0.16,  0.82,  0.48,
        0.88,  0.72,  0.81,  0.19,  0.86,  0.78,  0.22,  0.38,  0.61,
        0.23,  0.34,  0.14,  0.4 ,  0.05,  0.17,  0.68,  1.  ,  0.04,
        0.49,  0.24,  0.29,  0.02,  0.2 ,  0.97,  0.73,  0.15,  0.08,
        0.13,  0.27,  0.44,  0.59,  0.51,  0.1 ,  0.98,  0.03])

In [39]:

sns.factorplot('accuracy',data=merged_inner1,kind="count",hue='solved_status',order=[1,2,3,4,5,6,7,8,9,10])

Out[39]:

<seaborn.axisgrid.FacetGrid at 0x7f96bd07d650>

In [37]:

merged_inner1.rating.unique()

Out[37]:

array([ 4. ,  3.8,  0. ,  4.3,  5. ,  3.5,  2.6,  2.3,  4.5,  2.9,  1. ,
        3.7,  4.1,  3.3,  3.4,  3.1,  3.6,  4.8,  2.8,  3.9,  2.2,  4.7,
        3. ,  3.2,  4.4,  2. ,  4.2,  2.5,  2.1,  1.9,  2.7,  2.4,  4.6,
        1.8,  1.5])

In [55]:

merged_inner1['rating'] = merged_inner1['rating'].apply(np.round)

/home/anil/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  if __name__ == '__main__':

In [41]:

sns.factorplot('rating',data=merged_inner1,kind="count",size=5)

Out[41]:

<seaborn.axisgrid.FacetGrid at 0x7f96aff13950>

In [53]:

sns.factorplot('level',data=merged_inner1,kind="count",hue="solved_status",size=5)

Out[53]:

<seaborn.axisgrid.FacetGrid at 0x7fdd5900f7d0>

In [37]:

def transform_level(l):
    if(l == 'E'):
        return 0
    if(l == 'M'):
        return 1
    if(l == 'H'):
        return 2
    if(l == 'E-M'):
        return 3
    if(l == 'M-H'):
        return 4

In [38]:

merged_inner1['level'] = merged_inner1['level'].map(transform_level)

In [39]:

test_merged_inner1['level'] = test_merged_inner1['level'].map(transform_level)

In [40]:

merged_inner1 = merged_inner1.dropna()

In [41]:

merged_inner1.head()

Out[41]:
	user_id 	solved_count_x 	attempts 	problem_id 	solved_status 	level 	accuracy 	solved_count_y 	error_count 	rating
0 	1427919 	0 	11 	913736 	0 	1 	0.21 	524 	7868 	4
1 	1187633 	14 	20 	913736 	0 	1 	0.21 	524 	7868 	4
2 	1187633 	14 	20 	913736 	1 	1 	0.21 	524 	7868 	4
3 	1165859 	2 	14 	913736 	0 	1 	0.21 	524 	7868 	4
4 	1034822 	6 	11 	913736 	0 	1 	0.21 	524 	7868 	4
In [42]:

test_merged_inner1.head()

Out[42]:
	user_id 	solved_count_x 	attempts 	Id 	problem_id 	level 	accuracy 	solved_count_y 	error_count 	rating
0 	1444303 	0 	5 	14425 	940002 	0 	0.42 	63 	371 	3.7
1 	1461057 	0 	2 	18638 	940002 	0 	0.42 	63 	371 	3.7
2 	1002312 	0 	5 	9929 	940002 	0 	0.42 	63 	371 	3.7
3 	1002353 	14 	6 	20229 	940002 	0 	0.42 	63 	371 	3.7
4 	1068032 	84 	36 	25139 	940002 	0 	0.42 	63 	371 	3.7
In [43]:

from sklearn.cross_validation import train_test_split
X_train,X_test,Y_train,y_test = train_test_split(merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']],merged_inner1.solved_status)

In [47]:

X_train.count()

Out[47]:

solved_count_x    356733
level             356733
accuracy          356733
rating            356733
attempts          356733
solved_count_y    356733
dtype: int64

In [113]:

from sklearn.svm import LinearSVC
svm = LinearSVC(C=0.1)
svm.fit(X_train,Y_train)

svm.score(X_train,Y_train)

Out[113]:

0.6213582707515144

In [114]:

svm.score(X_test,y_test)

Out[114]:

0.62347786598493005

In [48]:

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=15,random_state=33)

In [49]:

rf.fit(X_train,Y_train)

rf.score(X_train,Y_train)

Out[49]:

0.8316780337114873

In [50]:

rf.score(X_test,y_test)

Out[50]:

0.57601419537136711

In [52]:

from sklearn import metrics
class_predict = rf.predict(X_test)
print metrics.accuracy_score(y_test,class_predict)

0.576014195371

In [53]:

from sklearn.metrics import mean_squared_error,r2_score
from sklearn.ensemble import GradientBoostingClassifier

In [54]:

clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, Y_train)
clf.score(X_train,Y_train)

Out[54]:

0.72319353690294985

In [55]:

clf.score(X_test,y_test)

Out[55]:

0.72005348493003229

In [44]:

from sklearn.ensemble import AdaBoostClassifier

In [45]:

clf1 = AdaBoostClassifier(n_estimators=100).fit(X_train,Y_train)

In [58]:

clf1.score(X_train,Y_train)

Out[58]:

0.72271138358380071

In [59]:

clf1.score(X_test, y_test)

Out[59]:

0.7192461652314317

In [60]:

from sklearn.cross_validation import cross_val_score
scores = cross_val_score(clf1,merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']],merged_inner1.solved_status)
print scores
print np.mean(scores)

[ 0.70161906  0.69844654  0.72420796]
0.708091186144

In [61]:

from sklearn.cross_validation import cross_val_score
scores = cross_val_score(clf,merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']],merged_inner1.solved_status)
print scores
print np.mean(scores)

[ 0.70165059  0.69898265  0.72335017]
0.707994472162

In [62]:

from sklearn.cross_validation import cross_val_score
scores = cross_val_score(rf,merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']],merged_inner1.solved_status)
print scores
print np.mean(scores)

[ 0.68320835  0.65001987  0.61637874]
0.649868984262

In [63]:

from sklearn import cross_validation

In [64]:

cv = cross_validation.KFold(len(merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']]), n_folds=10, indices=True, shuffle=True, random_state=4)

/home/anil/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:69: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17
  stacklevel=1)

In [65]:

scores = cross_val_score(clf1,merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']],merged_inner1.solved_status,cv=cv, n_jobs = 1)
print scores
print np.mean(scores)

[ 0.72151792  0.72454536  0.72010932  0.7205298   0.72366236  0.71932554
  0.72437137  0.72441342  0.71869481  0.72304684]
0.722021675291

In [66]:

x=merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']]
y=merged_inner1.solved_status
len(merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']])

Out[66]:

475645

In [1]:

for train_indices, test_indices in cv:
    print train_indices,test_indices
    clf1.fit(x[train_indices],y[train_indices])
    print clf1.score(x[test_indices],y[test_indices])
     

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-1-955d35933bd6> in <module>()
----> 1 for train_indices, test_indices in cv:
      2     print train_indices,test_indices
      3     clf1.fit(x[train_indices],y[train_indices])
      4     print clf1.score(x[test_indices],y[test_indices])
      5 

NameError: name 'cv' is not defined

In [48]:

X_test.head()

Out[48]:
	solved_count_x 	level 	accuracy 	rating 	attempts 	solved_count_y
108387 	18 	0 	0.84 	3.4 	45 	4333
23939 	24 	0 	0.56 	3.7 	46 	3916
178120 	17 	0 	0.89 	3.9 	15 	2349
242255 	10 	3 	0.33 	3.6 	12 	219
268951 	67 	0 	0.19 	3.8 	56 	469
In [55]:

test_merged_inner1.level.unique()

Out[55]:

array([ 0.,  2.,  1.,  3.,  4.])

In [56]:

test_predict = clf1.predict(test_merged_inner1[['solved_count_x','level','accuracy','rating','attempts','solved_count_y']])

In [57]:

test_predict_df = pd.DataFrame(test_predict)
test_predict_df.count()

Out[57]:

0    35618
dtype: int64

In [58]:

test_predict_df.to_csv('submission-2.csv')

In [54]:

test_merged_inner1['level'].fillna(0, inplace=True)

In [191]:

def importances(estimator, col_array, title): 
    # Calculate the feature ranking - Top 10
    importances = estimator.feature_importances_
    indices = np.argsort(importances)[::-1]
    print "%s Top 20 Important Features\n" %title
    for f in range(7):
        print("%d. %s (%f)" % (f + 1, col_array.columns[indices[f]], importances[indices[f]]))
#Mean Feature Importance
    print "\nMean Feature Importance %.6f" %np.mean(importances)

In [192]:

importances(rf, merged_inner1[['solved_count_x','attempts','accuracy','rating','level','solved_count_y']], "Cover Type (Initial RF)")

Cover Type (Initial RF) Top 20 Important Features

1. rating (0.381998)
2. solved_count_x (0.373921)
3. attempts (0.121063)
4. level (0.048026)
5. solved_count_y (0.043718)
6. accuracy (0.017844)
7. error_count (0.013429)

Mean Feature Importance 0.142857

In [15]:

merged_inner1.drop('error_count', axis=1, inplace=True)

merged_inner1.drop('solved_count_x', axis=1, inplace=True)

merged_inner1.drop('solved_count_y', axis=1, inplace=True)

merged_inner1.drop('accuracy', axis=1, inplace=True)

merged_inner1.drop('attempts', axis=1, inplace=True)

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-15-6d80535d7488> in <module>()
----> 1 merged_inner1.drop('error_count', axis=1, inplace=True)
      2 
      3 merged_inner1.drop('solved_count_x', axis=1, inplace=True)
      4 
      5 merged_inner1.drop('solved_count_y', axis=1, inplace=True)

NameError: name 'merged_inner1' is not defined

In [101]:

from sklearn.neighbors import KNeighborsClassifier
cls = KNeighborsClassifier()
cls.fit(X_train,Y_train)
print cls.score(X_train,Y_train)
print cls.score(X_test,y_test)

0.67098389372

---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-101-52b8ada7b6ed> in <module>()
      3 cls.fit(X_train,Y_train)
      4 print cls.score(X_train,Y_train)
----> 5 print cls.score(X_test,y_test)

/home/anil/anaconda/lib/python2.7/site-packages/sklearn/base.pyc in score(self, X, y, sample_weight)
    293         """
    294         from .metrics import accuracy_score
--> 295         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)
    296 
    297 

/home/anil/anaconda/lib/python2.7/site-packages/sklearn/neighbors/classification.pyc in predict(self, X)
    136         X = check_array(X, accept_sparse='csr')
    137 
--> 138         neigh_dist, neigh_ind = self.kneighbors(X)
    139 
    140         classes_ = self.classes_

/home/anil/anaconda/lib/python2.7/site-packages/sklearn/neighbors/base.pyc in kneighbors(self, X, n_neighbors, return_distance)
    372                     "or set algorithm='brute'" % self._fit_method)
    373             result = self._tree.query(X, n_neighbors,
--> 374                                       return_distance=return_distance)
    375         else:
    376             raise ValueError("internal: _fit_method not recognized")

KeyboardInterrupt: 

In [147]:

from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(rf,merged_inner1[['solved_count_x','accuracy']],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))

[ 0.69775905  0.71869623  0.72940404]
0.715286437243

In [18]:

from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(cls,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-18-bfeabb846b3c> in <module>()
      1 from sklearn.cross_validation import cross_val_score
      2 import numpy as np
----> 3 scores = cross_val_score(cls,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
      4 print (scores)
      5 print (np.mean(scores))

NameError: name 'merged_inner1' is not defined

In [19]:

from sklearn.cross_validation import cross_val_score
import numpy as np
scores = cross_val_score(svm,merged_inner1[['solved_count_x','solved_count_y','accuracy','rating']],merged_inner1.solved_status)
print (scores)
print (np.mean(scores))

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-19-f7e99e615668> in <module>()
      1 from sklearn.cross_validation import cross_val_score
      2 import numpy as np
----> 3 scores = cross_val_score(svm,merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
      4 print (scores)
      5 print (np.mean(scores))

NameError: name 'merged_inner1' is not defined

In [50]:

from sklearn.linear_model import LogisticRegression
from sklearn import metrics

log_model2 = LogisticRegression()

In [62]:

log_model2.fit(X_train,Y_train)

Out[62]:

LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr',
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0)

In [63]:

class_predict = log_model2.predict(X_test)
print metrics.accuracy_score(y_test,class_predict)

0.679485670075

In [1]:

from sklearn.feature_selection import RFE

In [51]:

rfe = RFE(log_model2, 1)
rfe = rfe.fit(merged_inner1.ix[:, merged_inner1.columns != 'solved_status'],merged_inner1.solved_status)
# summarize the selection of the attributes
print(rfe.support_)
print(rfe.ranking_)

[False False False False False  True False False False]
[9 3 5 8 2 1 6 7 4]

In [52]:

merged_inner1.columns

Out[52]:

Index([u'user_id', u'solved_count_x', u'attempts', u'problem_id',
       u'solved_status', u'level', u'accuracy', u'solved_count_y',
       u'error_count', u'rating'],
      dtype='object')

In [ ]:

 

