



In [1]:



import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

%matplotlib inline




In [2]:



import random
random.seed(2016)




In [3]:



df_train = pd.read_csv('train.csv')
#test = pd.read_csv('test.csv')
df_internship = pd.read_csv('Internship.csv')
df_student = pd.read_csv('Student.csv')




In [28]:



# Get basic information and print it.
n_samples = df_train.shape[0]
n_features = df_train.shape[1]
print "Number of training samples: {}".format(n_samples)
print "Number of features: {}".format(n_features)






Number of training samples: 192582
Number of features: 7




In [29]:



perc_mvs_per_col = (df_train.isnull().sum() / n_samples) * 100
print perc_mvs_per_col[perc_mvs_per_col > 0]






Series([], dtype: float64)




In [27]:



df_train.drop(['Preferred_location'],axis=1,inplace=True)




In [30]:



df_train[df_train.isnull().any(axis=1)].isnull().any()





Out[30]:

Internship_ID          False
Student_ID             False
Earliest_Start_Date    False
Expected_Stipend       False
Minimum_Duration       False
Is_Part_Time           False
Is_Shortlisted         False
dtype: bool



In [42]:



columns = ['Expected_Stipend','Minimum_Duration','Is_Part_Time']




In [32]:



df_train.head()





Out[32]:





Internship_ID

Student_ID

Earliest_Start_Date

Expected_Stipend

Minimum_Duration

Is_Part_Time

Is_Shortlisted



0
8161 78663553 03-01-2015 2-5K 3 0 0 

1
4977 7695797 19-12-2014 5-10K 2 1 0 

2
10271 78663092 06-01-2015 5-10K 6 0 0 

3
7393 7708503 03-12-2014 2-5K 1 0 0 

4
11125 78659782 02-01-2015 10K+ 6 1 0 



In [33]:



from sklearn import preprocessing
le = preprocessing.LabelEncoder()




In [40]:



le.fit(df_train.Expected_Stipend)
df_train.Expected_Stipend  = le.transform(df_train.Expected_Stipend)




In [44]:



merged_inner = pd.merge(df_student,df_train,on='Student_ID')




In [49]:



col = ['Student_ID','Internship_ID','Institute_Category','Degree','Stream','Current_year','Performance_PG','Year_of_graduation','PG_scale','Performance_UG','UG_Scale','Performance_12th','Performance_12th','Experience_Type','Expected_Stipend','Minimum_Duration','Is_Part_Time']
col1 = ['Institute_Category','Degree','Stream','Current_year','Experience_Type']




In [53]:



for i in col1:
    le.fit(merged_inner[i])
    merged_inner[i]  = le.transform(merged_inner[i])




In [57]:



X = merged_inner[col]




In [55]:



y = merged_inner.Is_Shortlisted




In [59]:



from sklearn.cross_validation import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y)




In [70]:



from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, roc_curve, auc
from sklearn.ensemble import GradientBoostingClassifier




In [72]:



#rf_initial=RandomForestClassifier(n_estimators=100, bootstrap=True, oob_score=True)
gbr = GradientBoostingClassifier(n_estimators=100)
gbr.fit(X_train,y_train)





Out[72]:

GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',
              max_depth=3, max_features=None, max_leaf_nodes=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              random_state=None, subsample=1.0, verbose=0,
              warm_start=False)



In [73]:



preds = gbr.predict(X_test)




In [74]:



print 'ROC AUC Score on the validation examples %f ' %(roc_auc_score(y_test, preds))






ROC AUC Score on the validation examples 0.500138 




In [20]:



# Get basic information and print it.
n_samples1 = df_internship.shape[0]
n_features1 = df_internship.shape[1]
print "Number of training samples: {}".format(n_samples)
print "Number of features: {}".format(n_features)






Number of training samples: 151191
Number of features: 19




In [22]:



perc_mvs_per_col = (df_internship.isnull().sum() / n_samples1) * 100
print perc_mvs_per_col[perc_mvs_per_col > 0]






Skills_required    86.200899
Stipend1            1.855341
Stipend2           54.326714
dtype: float64




In [23]:



# Get basic information and print it.
n_samples2 = df_student.shape[0]
n_features2 = df_student.shape[1]
print "Number of training samples: {}".format(n_samples)
print "Number of features: {}".format(n_features)






Number of training samples: 151191
Number of features: 19




In [24]:



perc_mvs_per_col = (df_student.isnull().sum() / n_samples2) * 100
print perc_mvs_per_col[perc_mvs_per_col > 0]






Degree              0.004630
Stream              0.033732
Experience_Type    20.423835
Profile            79.531189
Location            0.005953
Start Date         20.423835
End Date           56.371742
dtype: float64




In [ ]:



df_train[df_student.isnull().any(axis=1)].isnull().any()

