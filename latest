
In [4]:

import sys
import cPickle
import numpy as np
import pandas as pd
from nlp_utils import clean_text, pos_tag_text
sys.path.append("../")
#from param_config import config

In [5]:

print("Load data...")

dfTrain = pd.read_csv("train.csv").fillna("")
dfTest = pd.read_csv("test.csv").fillna("")
# number of train/test samples
num_train, num_test = dfTrain.shape[0], dfTest.shape[0]

print("Done.")

Load data...
Done.

In [6]:

print("Pre-process data...")

## insert fake label for test
dfTest["median_relevance"] = np.ones((num_test))
dfTest["relevance_variance"] = np.zeros((num_test))

Pre-process data...

In [7]:

## insert sample index
dfTrain["index"] = np.arange(num_train)
dfTest["index"] = np.arange(num_test)

In [8]:

## one-hot encode the median_relevance
for i in range(4):
    dfTrain["median_relevance_%d" % (i+1)] = 0
    dfTrain["median_relevance_%d" % (i+1)][dfTrain["median_relevance"]==(i+1)] = 1

/home/anil/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy

In [9]:

dfTrain.head()

Out[9]:
	id 	query 	product_title 	product_description 	median_relevance 	relevance_variance 	index 	median_relevance_1 	median_relevance_2 	median_relevance_3 	median_relevance_4
0 	1 	bridal shower decorations 	Accent Pillow with Heart Design - Red/Black 	Red satin accent pillow embroidered with a hea... 	1 	0.000 	0 	1 	0 	0 	0
1 	2 	led christmas lights 	Set of 10 Battery Operated Multi LED Train Chr... 	Set of 10 Battery Operated Train Christmas Lig... 	4 	0.000 	1 	0 	0 	0 	1
2 	4 	projector 	ViewSonic Pro8200 DLP Multimedia Projector 		4 	0.471 	2 	0 	0 	0 	1
3 	5 	wine rack 	Concept Housewares WR-44526 Solid-Wood Ceiling... 	Like a silent and sturdy tree, the Southern En... 	4 	0.000 	3 	0 	0 	0 	1
4 	7 	light bulb 	Wintergreen Lighting Christmas LED Light Bulb ... 	WTGR1011\nFeatures\nNickel base, 60,000 averag... 	2 	0.471 	4 	0 	1 	0 	0
In [10]:

## query ids
qid_dict = dict()
for i,q in enumerate(np.unique(dfTrain["query"]), start=1):
    qid_dict[q] = i

In [11]:

## insert query id
dfTrain["qid"] = map(lambda q: qid_dict[q], dfTrain["query"])
dfTest["qid"] = map(lambda q: qid_dict[q], dfTest["query"])

In [12]:

## clean text
clean = lambda line: clean_text(line, drop_html_flag=False)
dfTrain = dfTrain.apply(clean, axis=1)
dfTest = dfTest.apply(clean, axis=1)

print("Done.")

Done.

In [13]:

dfTrain.head()

Out[13]:
	id 	query 	product_title 	product_description 	median_relevance 	relevance_variance 	index 	median_relevance_1 	median_relevance_2 	median_relevance_3 	median_relevance_4 	qid
0 	1 	bridal shower decorations 	accent pillow with heart design - red/black 	red satin accent pillow embroidered with a hea... 	1 	0.000 	0 	1 	0 	0 	0 	31
1 	2 	led christmas lights 	set of 10 battery operated multi led train chr... 	set of 10 battery operated train christmas lig... 	4 	0.000 	1 	0 	0 	0 	1 	122
2 	4 	projector 	viewsonic pro8200 dlp multimedia projector 		4 	0.471 	2 	0 	0 	0 	1 	171
3 	5 	wine rack 	concept housewares wr-44526 solid-wood ceiling... 	like a silent and sturdy tree, the southern en... 	4 	0.000 	3 	0 	0 	0 	1 	250
4 	7 	light bulb 	wintergreen lighting christmas led light bulb ... 	wtgr1011\nfeatures\nnickel base, 60,000 averag... 	2 	0.471 	4 	0 	1 	0 	0 	128
In [14]:

from sklearn.cross_validation import StratifiedKFold

In [18]:

n_runs = 3
skf = [0]*n_runs
for stratified_label,key in zip(["relevance", "query"], ["median_relevance", "qid"]):
    for run in range(n_runs):
        random_seed = 2015 + 1000 * (run+1)
        skf[run] = StratifiedKFold(dfTrain[key], n_folds=3,
                                   shuffle=True, random_state=random_seed)
        for fold, (validInd, trainInd) in enumerate(skf[run]):
            print("================================")
            print("Index for run: %s, fold: %s" % (run+1, fold+1))
            print("Train (num = %s)" % len(trainInd))
            print(trainInd[:10])
            print("Valid (num = %s)" % len(validInd))
            print(validInd[:10])

================================
Index for run: 1, fold: 1
Train (num = 3386)
[ 3  8 10 11 12 20 21 22 28 33]
Valid (num = 6772)
[ 0  1  2  4  5  6  7  9 13 14]
================================
Index for run: 1, fold: 2
Train (num = 3386)
[ 2  5  6 14 16 17 18 19 23 25]
Valid (num = 6772)
[ 0  1  3  4  7  8  9 10 11 12]
================================
Index for run: 1, fold: 3
Train (num = 3386)
[ 0  1  4  7  9 13 15 24 27 30]
Valid (num = 6772)
[ 2  3  5  6  8 10 11 12 14 16]
================================
Index for run: 2, fold: 1
Train (num = 3386)
[ 0  1  9 11 17 21 27 28 31 34]
Valid (num = 6772)
[ 2  3  4  5  6  7  8 10 12 13]
================================
Index for run: 2, fold: 2
Train (num = 3386)
[ 3  5  6  8 10 14 23 25 26 30]
Valid (num = 6772)
[ 0  1  2  4  7  9 11 12 13 15]
================================
Index for run: 2, fold: 3
Train (num = 3386)
[ 2  4  7 12 13 15 16 18 19 20]
Valid (num = 6772)
[ 0  1  3  5  6  8  9 10 11 14]
================================
Index for run: 3, fold: 1
Train (num = 3386)
[ 1  3  8 10 11 12 13 14 15 19]
Valid (num = 6772)
[ 0  2  4  5  6  7  9 16 17 18]
================================
Index for run: 3, fold: 2
Train (num = 3386)
[ 4  5 16 18 22 24 27 30 32 38]
Valid (num = 6772)
[ 0  1  2  3  6  7  8  9 10 11]
================================
Index for run: 3, fold: 3
Train (num = 3386)
[ 0  2  6  7  9 17 20 28 29 33]
Valid (num = 6772)
[ 1  3  4  5  8 10 11 12 13 14]
================================
Index for run: 1, fold: 1
Train (num = 3470)
[ 0  4  5 12 14 16 18 20 22 29]
Valid (num = 6688)
[ 1  2  3  6  7  8  9 10 11 13]
================================
Index for run: 1, fold: 2
Train (num = 3393)
[ 3  8 13 15 19 24 25 26 27 32]
Valid (num = 6765)
[ 0  1  2  4  5  6  7  9 10 11]
================================
Index for run: 1, fold: 3
Train (num = 3295)
[ 1  2  6  7  9 10 11 17 21 23]
Valid (num = 6863)
[ 0  3  4  5  8 12 13 14 15 16]
================================
Index for run: 2, fold: 1
Train (num = 3470)
[ 2  6  7  9 10 12 14 15 16 17]
Valid (num = 6688)
[ 0  1  3  4  5  8 11 13 18 20]
================================
Index for run: 2, fold: 2
Train (num = 3393)
[ 0 13 18 24 25 38 39 40 42 43]
Valid (num = 6765)
[ 1  2  3  4  5  6  7  8  9 10]
================================
Index for run: 2, fold: 3
Train (num = 3295)
[ 1  3  4  5  8 11 20 22 23 30]
Valid (num = 6863)
[ 0  2  6  7  9 10 12 13 14 15]
================================
Index for run: 3, fold: 1
Train (num = 3470)
[ 0  3  7  8  9 13 16 20 26 27]
Valid (num = 6688)
[ 1  2  4  5  6 10 11 12 14 15]
================================
Index for run: 3, fold: 2
Train (num = 3393)
[ 2  6 11 12 14 19 21 22 24 28]
Valid (num = 6765)
[ 0  1  3  4  5  7  8  9 10 13]
================================
Index for run: 3, fold: 3
Train (num = 3295)
[ 1  4  5 10 15 17 18 23 25 31]
Valid (num = 6863)
[ 0  2  3  6  7  8  9 11 12 13]

In [30]:

from sklearn.preprocessing import LabelBinarizer
import os
print("==================================================")
print("Generate id features...")
id_names = [ "qid" ]
print("For cross-validation...")
for run in range(n_runs):
    ## use 33% for training and 67 % for validation
    ## so we switch trainInd and validInd
    for fold, (validInd, trainInd) in enumerate(skf[run]):
        print("Run: %d, Fold: %d" % (run+1, fold+1))
        path = "%s/Run%d/Fold%d" % ("/home/anil/Anil/kaggle/crowd-flower/test", run+1, fold+1)

            #################
            ## get id feat ##
            #################
        for id_name in id_names:
            lb = LabelBinarizer(sparse_output=True)
            X_train = lb.fit_transform(dfTrain.iloc[trainInd][id_name])
            X_valid = lb.transform(dfTrain.iloc[validInd][id_name])
            with open("%s/train.%s.feat.pkl" % (path, id_name),"wb") as f:
                cPickle.dump(X_train, f, -1)
            with open("%s/valid.%s.feat.pkl" % (path, id_name),"wb") as f:
                cPickle.dump(X_valid, f, -1)
                    
print("Done.")

==================================================
Generate id features...
For cross-validation...
Run: 1, Fold: 1
a+
Run: 1, Fold: 2
a+
Run: 1, Fold: 3
a+
Run: 2, Fold: 1
a+
Run: 2, Fold: 2
a+
Run: 2, Fold: 3
a+
Run: 3, Fold: 1
a+
Run: 3, Fold: 2
a+
Run: 3, Fold: 3
a+
Done.

In [33]:

print("For training and testing...")
path = "%s/All" % ("/home/anil/Anil/kaggle/crowd-flower/test")
    ## use full version for X_train                
for id_name in id_names:
    X_train = lb.fit_transform(dfTrain[id_name])
    X_test = lb.transform(dfTest[id_name])
    with open("%s/train.%s.feat.pkl" % (path, id_name), "wb") as f:
        cPickle.dump(X_train, f, -1)
    with open("%s/test.%s.feat.pkl" % (path, id_name), "wb") as f:
        cPickle.dump(X_test, f, -1)
print("Done.")
    
print("All Done.")

For training and testing...
Done.
All Done.

In [ ]:

 

